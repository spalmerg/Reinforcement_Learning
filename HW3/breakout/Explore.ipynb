{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym.spaces\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from collections import deque\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.95\n",
    "learning_rate = 0.01\n",
    "hidden_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 2D float array \"\"\"\n",
    "    image = image[35:195] # crop\n",
    "    image = image[::2,::2,0] # downsample by factor of 2\n",
    "    image[image == 144] = 0 # erase background (background type 1)\n",
    "    image[image == 109] = 0 # erase background (background type 2)\n",
    "    image[image != 0] = 1 # everything else just set to 1\n",
    "    return np.reshape(image.astype(np.float).ravel(), [80,80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Reset\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Breakout-v0')\n",
    "env.reset()\n",
    "print('Environment Reset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Value Estimator Network & Target Network\n",
    "class Network():\n",
    "    def __init__(self, learning_rate=0.01, hidden_size=10, action_size = 4, memory_size = 3, name=\"QEstimator\"):\n",
    "        with tf.variable_scope(name):\n",
    "            # Set scope for copying purposes\n",
    "            self.scope = name\n",
    "\n",
    "            # Store Variables\n",
    "            self.inputs_ = tf.placeholder(tf.float32, [None, memory_size, 80, 80], name='inputs')\n",
    "            self.target_preds_ = tf.placeholder(tf.float32, [None,], name=\"expected_future_rewards\")\n",
    "            self.chosen_action_pred = tf.placeholder(tf.float32, [None,], name=\"chosen_action_pred\")\n",
    "            self.actions_ = tf.placeholder(tf.int32, shape=[None], name='actions')\n",
    "            \n",
    "            # Three Convolutional Layers\n",
    "            self.conv1 = tf.contrib.layers.conv2d(self.inputs_, 32, 8, 4, activation_fn=tf.nn.relu)\n",
    "            self.conv2 = tf.contrib.layers.conv2d(self.conv1, 64, 4, 2, activation_fn=tf.nn.relu)\n",
    "            self.conv3 = tf.contrib.layers.conv2d(self.conv2, 64, 3, 1, activation_fn=tf.nn.relu)\n",
    "\n",
    "            # Fully Connected Layers\n",
    "            self.flatten = tf.contrib.layers.flatten(self.conv3)\n",
    "            self.fc1 = tf.contrib.layers.fully_connected(self.flatten, hidden_size)\n",
    "            self.predictions = tf.contrib.layers.fully_connected(self.fc1, action_size,\n",
    "                                                                 weights_initializer=tf.contrib.layers.xavier_initializer(), \n",
    "                                                                 activation_fn=None)\n",
    "            \n",
    "            # Get Prediction for the chosen action (epsilon greedy)\n",
    "            self.indices = tf.range(1) * tf.size(self.actions_) + self.actions_\n",
    "            self.chosen_action_pred = tf.gather(tf.reshape(self.predictions, [-1]), self.indices)\n",
    "            \n",
    "            # Calculate Loss\n",
    "            # self.losses = tf.squared_difference(self.target_preds_, self.chosen_action_pred)\n",
    "            self.losses = tf.losses.huber_loss(self.target_preds_, self.chosen_action_pred)\n",
    "            self.loss = tf.reduce_mean(self.losses)\n",
    "            \n",
    "            # Adjust Network\n",
    "            self.learn = tf.train.AdamOptimizer(learning_rate).minimize(self.losses)\n",
    "            \n",
    "    def predict(self, sess, state):\n",
    "        result = sess.run(self.predictions, feed_dict={self.inputs_: state})\n",
    "        return result\n",
    "    \n",
    "    def update(self, sess, state, action, target_preds):\n",
    "        feed_dict = {self.inputs_: state, \n",
    "                    self.actions_: action, \n",
    "                    self.target_preds_: target_preds}\n",
    "        loss = sess.run([self.loss, self.learn], feed_dict=feed_dict)\n",
    "        return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy Epsilon Policy\n",
    "Epsilon greedy policy chooses a random action a small fraction of the time. This epsilon can change throughout training, but this is more advanced.... so hold off on that for now @Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(sess, network, state, epsilon=0.99):\n",
    "    state = np.stack([state[0], state[1], state[2]])\n",
    "    state = np.expand_dims(state, axis=0)\n",
    "    pick = np.random.rand() # Uniform random number generator\n",
    "    if pick > epsilon: # If off policy -- random action\n",
    "        action = np.random.randint(0,4)\n",
    "    else: # If on policy\n",
    "        action = np.argmax(network.predict(sess, state))\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameter Copier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_parameters(sess, q_network, target_network):\n",
    "    \n",
    "    # Get and sort parameters\n",
    "    q_params = [t for t in tf.trainable_variables() if t.name.startswith(q_network.scope)]\n",
    "    q_params = sorted(q_params, key=lambda v: v.name)\n",
    "    t_params = [t for t in tf.trainable_variables() if t.name.startswith(target_network.scope)]\n",
    "    t_params = sorted(t_params, key=lambda v: v.name)\n",
    "    \n",
    "    # Assign Q-Parameters to Target Network\n",
    "    updates = []\n",
    "    for q_v, t_v in zip(q_params, t_params):\n",
    "        update = t_v.assign(q_v)\n",
    "        updates.append(update)\n",
    "    \n",
    "    sess.run(updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahgreenwood/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "QNetwork = Network(name = 'QNetwork', hidden_size=hidden_size, learning_rate=learning_rate)\n",
    "target = Network(name = 'Target', hidden_size=hidden_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-642e7abe2002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mreset_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mcopy_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQNetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mall_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-20f2dc9ce8fb>\u001b[0m in \u001b[0;36mcopy_parameters\u001b[0;34m(sess, q_network, target_network)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mupdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# saver = tf.train.Saver()\n",
    "buffer_size = 1000\n",
    "batch_size = 50\n",
    "epochs = 10\n",
    "reset_every = 10\n",
    "state_memory_size = 3\n",
    "\n",
    "buffer = deque(maxlen=buffer_size)\n",
    "state_memory = deque(maxlen=state_memory_size)\n",
    "all_result = []\n",
    "\n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Set up count for network reset\n",
    "    count = 0\n",
    "    \n",
    "    # Set up memory for episode\n",
    "    start_state = preprocess(env.reset())\n",
    "    for fill in range(state_memory_size):\n",
    "        state_memory.append(start_state)\n",
    "    \n",
    "    # Fill The Buffer\n",
    "    for i in range(buffer_size):\n",
    "        action = epsilon_greedy(sess, QNetwork, state_memory)\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # Save old_state_memory\n",
    "        old_state_memory = state_memory\n",
    "        \n",
    "        # Add new_state to state_memory\n",
    "        state_memory.append(preprocess(new_state))\n",
    "        \n",
    "        # Add step to buffer\n",
    "        buffer.append([old_state_memory, action, state_memory, reward])\n",
    "        \n",
    "        # If done, reset memory\n",
    "        if done: \n",
    "            start_state = preprocess(env.reset())\n",
    "            for fill in range(state_memory_size):\n",
    "                state_memory.append(start_state)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Set Up Memory\n",
    "        start_state = preprocess(env.reset())\n",
    "        for fill in range(state_memory_size):\n",
    "            state_memory.append(start_state)\n",
    "\n",
    "        result = []\n",
    "        while True: \n",
    "            # Add M to buffer (following policy)\n",
    "            action = epsilon_greedy(sess, QNetwork, state_memory)\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            # Save old_state_memory\n",
    "            old_state_memory = state_memory\n",
    "            \n",
    "            # Add new_state to state_memory \n",
    "            state_memory.append(preprocess(new_state))\n",
    "            \n",
    "            # Add step to buffer\n",
    "            buffer.append([old_state_memory, action, state_memory, reward])\n",
    "            \n",
    "            # If simulation done, stop\n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "            ### Sample & update\n",
    "            sample = random.sample(buffer, batch_size)\n",
    "            state_b, action_b, new_state_b, reward_b = map(np.array, zip(*sample))\n",
    "\n",
    "            # Find max Q-Value per batch for progress\n",
    "            Q_preds = sess.run(QNetwork.chosen_action_pred, \n",
    "                                 feed_dict={QNetwork.inputs_: state_b,\n",
    "                                 QNetwork.actions_: action_b})\n",
    "            result.append(np.max(Q_preds))\n",
    "        \n",
    "            # Target Network Predictions + Discount\n",
    "            TPredictions = target.predict(sess, new_state_b)\n",
    "            max_Qt = gamma * np.max(TPredictions, axis=1)\n",
    "            action_Ts = reward_b + max_Qt\n",
    "\n",
    "            # Update Q-Network\n",
    "            loss, _ = QNetwork.update(sess, state_b, action_b, action_Ts)\n",
    "            \n",
    "            # save target network parameters every epoch\n",
    "            count += 1\n",
    "            if count % reset_every == 0:\n",
    "                copy_parameters(sess, QNetwork, target)\n",
    "        \n",
    "        all_result.append(np.mean(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1300792b0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130fa3b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
